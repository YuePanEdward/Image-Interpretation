{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Interpretation – Assignment 5\n",
    "\n",
    "This assignment on __Deep Convolutional Neural Networks__ covers the deep networks labs from 8th and 15th of November, and is graded by a maximum of 9 points.\n",
    "\n",
    "In order to submit the results, send a ZIP file with your implemented code (functions prefixed with ii and any “helper” functions you wrote) to <riccardo.delutio@geod.baug.ethz.ch> with subject [Image Interpretation 2018 Assignment 5] no later than on the 21st of November, 2018.\n",
    "\n",
    "In addition to the code, include a report (__max. 8 pages__ PDF) explaining the structure of the code and the python/Matlab functions used. This includes the reasons for choosing particular functions as well as a short justification of their parameter setting. For the more complicated tasks, the choice of the underlying\n",
    "data structures and algorithms should be explained too. We encourage you to add also diagrams, illustrations, and figures into the report when appropriate, but it is not necessary to copy the related theory from the lecture slides. The report should not contain any code snippets (but the code should contain comments if appropriate). \n",
    "\n",
    "__Team work is not allowed__. Everybody implements his/her own code and writes his/her own report. Discussing issues with others is fine, sharing code and/or report with others is __not__. If you use any code fragments found on the Internet, make sure you reference them properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1, 2pts\n",
    "\n",
    "In this first exercise we are going to get an idea on how simple neural networks\n",
    "behave for simple classification tasks. We’ll make use of two different javascript\n",
    "based neural network to train and modify an existing model. Let’s start with a very\n",
    "simple one, a simple neural network with only fully connected layers and without\n",
    "convolutions. Open a web browser on the page http://playground.tensorflow.org/ and start playing with the interface. For each dataset set the noise level to 30. Click play on the top-left to start training. To assess the quality of the network look at the values train and test loss at the top right. Tip: Sometimes it’s easier\n",
    "to see the result if you discretise the graph.\n",
    "\n",
    "1. For each dataset (the four boxes under DATA) explore the best features that\n",
    "make the network converge faster.\n",
    "2. For the spiral dataset and default network how does the batch size (bottom\n",
    "left slider) influence the results? How does it relate with the learning rate\n",
    "(central top)?\n",
    "3. Try all the different activation layers (top slider), what are their differences?\n",
    "Why?\n",
    "4. How does the number of hidden layers and the number of neuron per\n",
    "\tlayer affect the results in terms of quality (test loss) and convergence\n",
    "\tspeed?\n",
    "5. Compare the performance (convergence rate and accuracy) of a network for regression and classification? Explain the differences.\n",
    "6. Play with different types and rates of regularization (top slider) and explain the changes you observe and the influence on the results.\n",
    "\n",
    "Explain each question and motivate it with a screenshot of the experiment.\n",
    "\n",
    "__The following part is optional, but fun!__ Open this page https://cs.stanford.edu/people/karpathy/convnetjs/demo/mnist.html and try to tweak all the pa-\n",
    "rameters you can to obtain the best network (the highest validation accuracy).\n",
    "Scroll down the page and peek inside the network and have a look at different\n",
    "activation and weight as the network gets trained (click pause to make it freeze).\n",
    "Check how the prediction works on the test set in the last part of the page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2, 3pts\n",
    "\n",
    "In this exercise you have to train a new Convolutional Neural Network from scratch for the classification of images.\n",
    "1. For this we will use the [Keras](https://keras.io/) library. You can download it on your `conda` environment with `conda install keras-gpu`.\n",
    "2. The aim is to achieve 99% accuracy (on validation/test set) the MNIST dataset http://yann.lecun.com/exdb/mnist/. We have provided a basic Keras implementation of a CNN.\n",
    "3. You are allowed to do whatever you want (except copy pasting) with the\n",
    "network as long as it is explained in your report. Feel free to change the architecture\n",
    "of the network as well as parameters (e.g. learning rate, kernel sizes, ...). You\n",
    "can try to guess parameters manually of you want, just make sure that it\n",
    "performs better than 99% on the validation set.\n",
    "4. Sketch the final network architecture in your report.\n",
    "5. Make sure you train the network on the GPU, otherwise it will be too slow.\n",
    "6. Explain the plots that appear.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "x_test shape: (10000, 28, 28, 1)\n",
      "y_train shape: (60000,)\n",
      "y_test shape: (10000,)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoUAAALICAYAAAAJ74pmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAIABJREFUeJzt3XmUXlWZL/7vDgmQgAEZGlAuBAQFRYggDnQu0M0QRQSUlqEZhFawoRFxNTS2jYoyOCG3QQRnFOEKXhGC/qSB7jAo04VG7MUQUJQwDyohIUBiyPn9UYU3jWdXeJOqeqve+nzWyjJ5dj3nPDF1ki+nsndK0zQBAGBsG9ftAQAA6D6hEAAAoRAAAKEQAIAIhQAARCgEACBCITDClVI2KKU8U0pZYQTM8j9LKfd0e45lVUo5oJRyZbfnAEYmoRAYEUop95dSnusPgC9+e1XTNA80TbNq0zQvLMM1Dyml/HwpH/PqUsqMUsofSikPlVL+vvaxTdP8rGma13U6x0jRNM0FTdPsuiy9pZQTSylNKeXol9SP6a+f2P/jHft//JWXfNzPSymH9H//v/26lFKmlVJuKKU83f/rcH0pZdtSyseX+Fx4vpTywhI/vnNZfh5AnVAIjCTv7g+AL357ZKAPLn2W9/ex85P8Nsk6Sd6V5NRSyl8t5zV71b1J3v+S2sH99SXNT3JwKWXK0i5YSpmc5CdJvpxkjSSvTvLpJAuapjn1xc+FJH+f5MYlPjfesFw/E+DPCIXAiFZKmdL/5ml8/4+vKaWcUkq5PsmzSTbuf/P0m1LKvFLKb/u/TLp5kq8meXv/m6U5LddeNcmOSU5pmuaPTdP8MskPk/xdZZYdSykPLfHj+0spx5VS/quUMr+U8q1SyjqllMv7Z/n3Usorl/j4/1NKeaz/jdh1pZQ3LLG2Zinlx6WUuaWUW0opJ7/kbdpmpZSr+t+k3VNK2WeJtd1KKXf13/PhUsqxlflf+oauKaX8fSnlV6WUp0opXymllAF+OW5JMunFufv/d2J/fUlzknwnyacGuNaLXpskTdN8v2maF5qmea5pmiubpvmvl9ELDCKhEBiNDkpyeJJXJHkyyZlJ3tk0zSuSbJfk9qZp7s5/f7u0est1ykv+98Xvb9HBLHsn2SV94ebdSS5P8vEka6Xv99glv9x6eZJNk/xFktuSXLDE2lfS94Zt3fS9jfvTG7lSyipJrkryv/t7909y9hKh8ltJPtT/898iycwO5t89ybZJtkqyT5LpS/n476Xv7WD6Zzyv8nGnJNm7lLK0L7ffm+SFUsp3SynvXDJEA8NLKARGkktLKXP6v106wMd9p2maO5umWZRkUZLFSbYopUxsmubRpmle1t83a5pmXpLrk3yilLJyKWXr9IW8SR3M/OWmaR5vmubhJD9LcnPTNL9ommZBkkuSvGmJ+327aZp5/WsnJtmqlLJa/yaavZN8qmmaZ5umuSvJd5e4x+5J7m+a5tymaRY1TXNbkouT/E3/+h+TvL6UMrlpmqf611+uzzVNM6dpmgeSXJ1k6lI+/vwk+5dSJiTZr//Hf6ZpmsfS96b2MwNdrGmauUmmJWmSfCPJk6WUy0op63TwcwAGgVAIjCR7NU2zev+3vQb4uAdf/E7TNPOT7Ju+t4KPllL+v1LKZh3c84AkG/Vf85z0vb17aMCO/+7xJb7/XMuPV02SUsoKpZTPlVLuK6XMTXJ//8eslWTtJOOX/Hm95PsbJnnrEoF5Tv/c6/av751ktySzSynXllLe3sH8jy3x/WdfnLemPzz+OsmpSX7VNM2DA3z455NML6VstZRr3t00zSFN06yfvjedr0ryry9neGDwCIXAaNT8tx80zRVN0+ySZL0ks9L3xunPPq71Qk0zu2ma3ZumWbtpmrcmWTPJ/x3sgZP8bZI9k+ycZLUkU/rrJX1fAl+UZP0lPv5/LPH9B5Ncu0RgXr3/S+JH9P8cbmmaZs/0fWn50iQ/GIL5l3Rekn9M/UvH6Z/r9+kLdye93As3TTMrfX8fsZMv4QODQCgERrX+jR179P+9uwVJnkny4vE1jydZv5Sy4gD9m5dSXlFKWbGUcmCSXZOcPgSjvqJ/vt+n78vTp7640H/czo+SnFhKmdT/pvPgJXp/kuS1pZSDSikT+r9t2z/7iv0ba1ZrmuaPSebm//38h8pF6fv/6eWEz9PT9/c8N29b7N9A84+llPX7f/w/0vd3Jm8apFmBl0koBEa7cel7a/VIkj8k2SHJkf1rM5PcmeSxUsrvKv3Tk/wmyVPp+xL0O5qmeXII5jwvyewkDye5K38eeo5K3xvEx9K3meP76QuRL/7dx13T93f4Hun/mM8nWam/96Ak9/d/Wfrvkxw4BPP/Sf8O4X9vmua5l/Gxc5N8IX3HzbSZl+StSW4upcxP3/8vd6Tv1xQYRqVplvrVFQCGWSnl80nWbZrmpecCAgwJbwoBRoD+L6Nu2X8g91uSfCB9u5cBhsX4bg8AQJK+v3P4/fTtvH0iyZeSzOjqRMCY4svHAAD48jEAAEIhAAARCgEAiFAIAECEQgAAIhQCABChEACACIUAAEQoBAAgQiEAABEKAQCIUAgAQIRCAAAiFAIAEKEQAIAIhQAARCgEACBCIQAAEQoBAIhQCABAhEIAACIUAgAQoRAAgAiFAABEKAQAIEIhAAARCgEAiFAIAECEQgAAIhQCABChEACACIUAAEQoBAAgQiEAABEKAQCIUAgAQIRCAAAiFAIAEKEQAIAIhQAARCgEACBCYc8ppVxTSnm+lPJM/7d7uj0TjHallKNKKbeWUhaUUr7T7XmgV3i2Rpbx3R6AIXFU0zTf7PYQ0EMeSXJykulJJnZ5Fuglnq0RRCgEWIqmaX6UJKWUNydZv8vjQM/wbI0svnzcmz5bSvldKeX6UsqO3R4GABj5hMLec3ySjZO8OsnXk/y4lPKa7o4EAIx0QmGPaZrm5qZp5jVNs6Bpmu8muT7Jbt2eCwAY2YTC3tckKd0eAgAY2YTCHlJKWb2UMr2UsnIpZXwp5YAk2ye5otuzwWjW/zytnGSFJCu8+Ix1ey4Y7TxbI4tQ2FsmpG9r/5NJfpfkw0n2aprGWYWwfE5I8lySjyU5sP/7J3R1IugNnq0RpDRN0+0ZAADoMm8KAQAQCgEAEAoBAIhQCABAhEIAAJIM61lApRRbnek5TdN0/XBwzxa9yLMFQ6P2bHlTCACAUAgAgFAIAECEQgAAIhQCABChEACACIUAAEQoBAAgQiEAABEKAQCIUAgAQIRCAAAiFAIAEKEQAIAIhQAARCgEACBCIQAAEQoBAIhQCABAhEIAACIUAgAQoRAAgAiFAABEKAQAIMn4bg8AAPSWM844o7V+9NFHV3vuuOOO1vruu+9e7Zk9e3ZngzEgbwoBABAKAQAQCgEAiFAIAECEQgAAYvfxqLDCCiu01ldbbbVBvc9RRx3VWp80aVK153Wve11r/R/+4R+qPaeddlprff/996/2PP/88631z33uc9WeT3/609U1GOlOOOGE1vpAn9fjxrX/d/6OO+5Y7bn22ms7mgteNGXKlOragQce2FpfvHhxtWfzzTdvrW+22WbVHruPB5c3hQAACIUAAAiFAABEKAQAIEIhAAARCgEAiCNplssGG2zQWl9xxRWrPdttt11rfdq0adWe1VdfvbW+9957DzDd8HjooYda62eeeWa15z3veU9rfd68edWeX/7yl611x2kwmh1yyCHVteOPP761PtCRHjVN03TcA0vz5JNPVteuu+661voee+wxVOMwCLwpBABAKAQAQCgEACBCIQAAEQoBAIjdx0s1derU6trMmTNb66utttpQjdMVA+12POGEE1rrzzzzTLXnggsuaK0/+uij1Z6nnnqqtX7PPfdUe2Ck23DDDatrK6+88jBOAp2bP39+dW327NnDOAmDxZtCAACEQgAAhEIAACIUAgAQoRAAgAiFAADEkTRL9cADD1TXfv/737fWR8KRNDfffHNrfc6cOdWev/qrv2qtL1y4sNrzve99r7PBYAzaeeedW+sf/vCHO77WrFmzqmu77757a/3xxx/v+D6wNKuvvnp1bautthrGSRgs3hQCACAUAgAgFAIAEKEQAIAIhQAAxO7jpfrDH/5QXTvuuONa67UdgEnyi1/8orV+5plndjZYkttvv726tssuu7TWB/oHzN/whje01j/ykY90NhiMQdOmTauunXvuua31ZTmp4Itf/GJ1bfbs2R1fD5bVpEmTqmsbbLDBoN1n2223ra7VduN7FpaNN4UAAAiFAAAIhQAARCgEACBCIQAAEQoBAEhSmqYZvpuVMnw366LJkydX1+bNm9da/9rXvlbt+cAHPtBaP/DAA6s93//+96trDK6maUq3Zxgrz9ZI9o1vfKO69nd/93cdX++aa65pre+0004dX2u08myNXp/4xCda6yeeeGK1Z1nyyDHHHNNaP+usszq+1lhSe7a8KQQAQCgEAEAoBAAgQiEAABEKAQBIMr7bA/SiuXPndtzz9NNPd9xz2GGHVdcuuuii1vrixYs7vg/w/6y11lqt9YF2GNeeuzlz5lR7Tj755M4GgxHkpJNOaq0PtPuY7vOmEAAAoRAAAKEQAIAIhQAARCgEACBCIQAAcSTNiDHQNv1tttmmtb7DDjtUe3beeefW+pVXXtnRXDAWTZkypbp28cUXD9p9vvzlL1fXrr766kG7D4wU48bV30U5Mq37vCkEAEAoBABAKAQAIEIhAAARCgEAiN3HI8b8+fOra4cddlhr/bbbbqv2fOMb32itD7Sj8dZbb22tf+UrX6n2NE1TXYPR6h3veEd1bcstt+z4ev/xH//RWj/jjDM6vhaMZgPtMPbnSfd5UwgAgFAIAIBQCABAhEIAACIUAgAQoRAAgDiSZlS47777WuuHHHJItefcc89trR900EHVntraKqusUu0577zzWuuPPvpotQdGir322qu1/rnPfa7ja/385z+vrr3//e9vrT/99NMd3wdgqHhTCACAUAgAgFAIAECEQgAAIhQCABC7j0e1Sy65pLr2q1/9qrV++umnV3t22mmn1vqpp55a7dlwww1b66ecckq15+GHH66uwWCbMmVKde3iiy8etPv85je/qa49/vjjg3YfgKHiTSEAAEIhAABCIQAAEQoBAIhQCABAhEIAAJKUpmmG72alDN/NaLX66qtX19797ne31s8999xqTymltT5z5sxqzy677FJdG42apmn/P2EYebbqzjnnnOraBz/4wUG7zxZbbFFdu+eeewbtPmOJZ6v3DJQ5Fi9e3PH1asdK7bPPPh1fayypPVveFAIAIBQCACAUAgAQoRAAgAiFAADE7mNehgULFlTXxo8f31pftGhRtWf69Omt9WuuuaajuUYKOyRHhqlTp7bWa7sTk2SDDTbo+D4zZsxorf/N3/xNx9diYJ6t3vPCCy9U1wYzj2y55ZbVtbvuumvQ7jNa2X0MAECVUAgAgFAIAIBQCABAhEIAACIUAgCQpP08EUa92nb8gY7N2HbbbVvrtWNnBjLQlv/rrruu4+vB0lx55ZWt9Ve+8pUdX+umm26qrh1yyCEdXw/o89WvfrW69qEPfWjQ7nP44YdX14455phBu0+v8aYQAAChEAAAoRAAgAiFAABEKAQAIHYfjwqve93rWutHHXVUtee9731va33dddcdlJleVPvHzR999NFqz+LFiwd1BkiSNddcs7W+LJ9vZ599dnXtmWee6fh6QJ9Zs2Z1ewQG4E0hAABCIQAAQiEAABEKAQCIUAgAQIRCAACSlKZphu9mpQzfzUao2pEw+++/f7WndvTMlClTBmOkpbr11lura6ecckpr/bLLLhuqcUacpmlKt2cYK8/WueeeW1075JBDWuvLciTNxhtvXF2bPXt2x9dj2Xi2xpZ77723tf6a17ym42uNG1d/57XJJpu01u+7776O7zNa1Z4tbwoBABAKAQAQCgEAiFAIAECEQgAAkozv9gCj2TrrrNNaf/3rX1/tOeuss1rrm2222aDMtDQ333xzde2LX/xia33GjBnVnmXZ2QlLM3Xq1Nb6zjvvXO2pfS4uXLiw2vOVr3yltf74448PMB0wFO68887W+kCnAdT4s2nZeFMIAIBQCACAUAgAQIRCAAAiFAIAEKEQAIA4kuZP1lhjjdb61772tWpP7diMZdk+vyxuuOGG6tqXvvSl1voVV1xR7XnuueeWeyYYDKuvvnprfd111+34Wg8//HB17dhjj+34esDQ+PrXv95af/e73z3Mk4xd3hQCACAUAgAgFAIAEKEQAIAIhQAApEd3H7/1rW9trR933HHVnre85S2t9Ve/+tWDMtPSPPvss9W1M888s7V+6qmnVnvmz5+/3DMBwHC56667Wut33313tWfzzTcfqnHGJG8KAQAQCgEAEAoBAIhQCABAhEIAACIUAgCQHj2S5j3veU9H9WVV2z7/k5/8pNqzaNGi1vqXvvSlas+cOXM6GwxGuVmzZrXWb7jhhmrPtGnThmocYBjMnj27tf7GN75xmCcZu7wpBABAKAQAQCgEACBCIQAAEQoBAEhSmqYZvpuVMnw3g2HSNE3p9gyeLXqRZwuGRu3Z8qYQAAChEAAAoRAAgAiFAABEKAQAIEIhAAARCgEAiFAIAECEQgAAIhQCABChEACACIUAAEQoBAAgQiEAABEKAQCIUAgAQIRCAAAiFAIAEKEQAIAkpWmabs8AAECXeVMIAIBQCACAUAgAQIRCAAAiFAIAEKEQAIAIhQAARCgEACBCIQAAEQoBAIhQCABAhEIAACIUAgAQoRAAgAiFAABEKAQAIEIhAAARCgEAiFDYc0opa5RSLimlzC+lzC6l/G23Z4LRrpSyeSllZinl6VLKr0sp7+n2TNArSinnl1IeLaXMLaXcW0r5YLdnGquEwt7zlSQLk6yT5IAk55RS3tDdkWD0KqWMTzIjyU+SrJHk8CTnl1Je29XBoHd8NsmUpmkmJ9kjycmllG26PNOYJBT2kFLKKkn2TvKJpmmeaZrm50kuS3JQdyeDUW2zJK9K8r+apnmhaZqZSa6P5woGRdM0dzZNs+DFH/Z/e00XRxqzhMLe8tokLzRNc+8StV8m8aYQll2p1LYY7kGgV5VSzi6lPJtkVpJHk/y0yyONSUJhb1k1ydMvqT2d5BVdmAV6xawkTyQ5rpQyoZSya5Idkkzq7ljQO5qmOTJ9f1b9zyQ/SrJg4A6GglDYW55JMvkltclJ5nVhFugJTdP8McleSd6V5LEk/5jkB0ke6uZc0Gv6/3rGz5Osn+SIbs8zFgmFveXeJONLKZsuUdsqyZ1dmgd6QtM0/9U0zQ5N06zZNM30JBsn+b/dngt61Pj4O4VdIRT2kKZp5qfvtftnSimrlFL+MsmeSb7X3clgdCulbFlKWbmUMqmUcmyS9ZJ8p8tjwahXSvmLUsp+pZRVSykrlFKmJ9k/ycxuzzYWCYW958gkE9P3d6C+n+SIpmm8KYTlc1D6/vL7E0l2SrLLErslgWXXpO9LxQ8leSrJaUmOaZpmRlenGqNK0zTdngEAgC7zphAAAKEQAAChEACACIUAAEQoBAAgfQdEDptSiq3O9Jymadr+bdxh5dmiF3m2YGjUni1vCgEAEAoBABAKAQCIUAgAQIRCAAAiFAIAEKEQAIAIhQAARCgEACBCIQAAEQoBAIhQCABAhEIAACIUAgAQoRAAgAiFAABEKAQAIEIhAAARCgEAiFAIAECEQgAAIhQCABChEACACIUAACQZ3+0BGF7bbLNNde2oo45qrR988MHVnvPOO6+1/uUvf7nac9ttt1XXAIDu8KYQAAChEAAAoRAAgAiFAABEKAQAIElpmmb4blbK8N1sjJs6dWprfebMmdWeyZMnD9r9n3766erammuuOWj3GQmapindnsGzRS/ybI1sr33ta6trEyZMaK1vv/321Z6zzz67tb548eLOBhsCM2bMaK3vt99+1Z6FCxcO1TjLrfZseVMIAIBQCACAUAgAQIRCAAAiFAIAEKEQAIA4kmZUe8tb3lJdu/jii1vrr3rVq6o9tc+FefPmVXtqW+4HOnZm2rRprfXbbrut4/uMBI7NgKHh2Ro+b3jDG6prhxxySGv9fe97X7Vn3Lj2d04D/RlUSvsv93DmlE6dd9551bVjjjmmtT537tyhGudlcyQNAABVQiEAAEIhAABCIQAAEQoBAIjdxyPGpEmTqmtbb711a/3888+v9qy//vqt9drurqS+w2ugXcFf+MIXWusXXnhhtac2wwknnFDt+exnP1td6zY7JEevt771ra31Aw88sNqzww47tNYH2r1Zc+yxx1bXHnnkkdZ6bfd+Uv894eabb+5ssBHCszV8LrvssurabrvtNiwzjMbdxwOp/V5x/fXXD/Mkf87uYwAAqoRCAACEQgAAhEIAACIUAgAQoRAAgCTjuz0Afb72ta9V1/bff/9hnOTP1Y7ESZJVV121tX7ttddWe3bcccfW+pZbbtnRXPBy7LvvvtW1M844o7W+1lprVXtqx2Zcc8011Z611167tf7FL36x2tPp/Qe6z3777dfxfRhbrrrqqurashxJ88QTT7TWv/Wtb1V7xo1rf0+1ePHiju+/3XbbVddqR8XgTSEAABEKAQCIUAgAQIRCAAAiFAIAELuPh90222zTWn/Xu95V7Rlot2FNbffvj3/842rPaaed1lp/5JFHqj2/+MUvWutPPfVUteev//qvW+vL8vNkbBk/vv5b1pvf/ObW+je+8Y1qz6RJk1rr1113XbXnpJNOaq3//Oc/r/astNJKrfUf/OAH1Z5dd921ulZz6623dtwDSXLOOedU1y699NKOr/fHP/6xtf7YY491fK1lMXny5OraHXfc0Vp/1ate1fF9Bvr/ZjQ+j94UAgAgFAIAIBQCABChEACACIUAAEQoBAAgjqQZElOnTq2u1f7R8YG2zzdN01q//PLLqz37779/a32gfwj8hBNOaK1/85vfrPY8+eSTrfVf/vKX1Z7aP24+0LE8W2+9dWv9tttuq/bQew488MDq2kCfpzW153Hfffet9sydO7fj+9SutyzHzjz00EPVte9+97sdXw+SZNGiRdW1Bx98cBgnGRzTp0+vrr3yla8ctPsM9DwuWLBg0O4zXLwpBABAKAQAQCgEACBCIQAAEQoBAEhSajtbh+RmpQzfzYbBa1/72tb6pz71qWrPfvvt11r/3e9+V+159NFHW+snn3xyteeHP/xhda3bXnjhhdb6QJ+LF110UWv9gAMOGJSZlkfTNKXbM/Tas3XSSSe11j/+8Y9Xe2qfP2effXa1p7bjfll2GA/k7rvvbq1vuummHV9r7733rq7NmDGj4+uNZJ4tlqb2Z+phhx1W7RnoFI5OrbHGGtW1wf59ZDDVni1vCgEAEAoBABAKAQCIUAgAQIRCAAAiFAIAkGR8twcY6VZaaaXq2mmnndZa32233ao98+bNa60ffPDB1Z5bb721tT5x4sRqT6/ZYIMNuj0Cg+yTn/xkda129MzChQurPVdccUVr/fjjj6/2PPfcc9W1mpVXXrm1vuuuu1Z7ap+/pdRPXKkdOdVrx87Ai2pHjH3sYx+r9myyySat9QkTJgzKTC+6/fbbW+t//OMfB/U+3eZNIQAAQiEAAEIhAAARCgEAiFAIAEDsPl6qN73pTdW1gXYZ1+y5556t9Wuvvbbja8FosPrqq7fWjzzyyGpP0zSt9doO4yTZa6+9OhtsALUdjUlywQUXtNa32Wabju/zwx/+sLr2hS98oePrwbKaMmVKde2ggw5qre+8886DOsO0adNa67XfD5bV3LlzW+sD7XL+6U9/2lpflhMMRjJvCgEAEAoBABAKAQCIUAgAQIRCAAAiFAIAEEfSLNXpp59eXav9Y/YDHS/j6Jlk3Lj2/xZZvHjxME/CcFhxxRVb62uttVbH1zr66KOra3/xF3/RWj/00EOrPXvssUdrfYsttqj2rLrqqq31gY7NqK2df/751Z758+dX12BZ1T63L7vssmrPBhtsMFTjdMXPfvaz1vrXv/71YZ5k5PGmEAAAoRAAAKEQAIAIhQAARCgEACB2H//J7rvv3lqfOnVqtae2o3CgXVzUdxkPtHvz9ttvH6pxGGILFy5srT/55JPVnrXXXru1/tvf/rbaM9DnT6ceeeSR6trcuXNb6+utt16153e/+11r/cc//nFng8EQqZ2msbS1wTRcJ1PU/rx/5zvfWe25/PLLB3WGkcqbQgAAhEIAAIRCAAAiFAIAEKEQAIAIhQAAxJE0fzJx4sTW+oorrljteeKJJ1rrF1100aDMNBqstNJKrfUTTzyx42vNnDmzuvbP//zPHV+PkWHOnDmt9b322qva85Of/KS1vsYaa1R77rvvvtb6jBkzqj3f+c53Wut/+MMfqj0XXnhha32gI2lqPTDc7rjjjtb6jjvuWO058MADW+tXXHFFtef555/vaK5l9YEPfKC1/uEPf3hY7t9rvCkEAEAoBABAKAQAIEIhAAARCgEAiN3Hy2XBggWt9UcffXSYJxlatR3GSXLCCSe01o877rhqz0MPPdRa/9KXvlTteeaZZ6prjE4333xzdW3ttdcexkn+3Pbbb19d22GHHVrrixcvrvb85je/We6ZYCjNnj27unbKKacM4ySdqZ10YffxsvGmEAAAoRAAAKEQAIAIhQAARCgEACBCIQAAcSTNcrnsssu6PcKgmjp1amt9oONl9t1339b6jBkzqj177713Z4PBMJs4cWJ1rXb0TNM01Z4LL7xwuWcC/tz06dO7PUJP8aYQAAChEAAAoRAAgAiFAABEKAQAIHYf/0kppaN6kuy1116t9Y985CODMtNQ+OhHP1pd+8QnPtFaX2211ao9F1xwQWv94IMP7mwwGEGuuOKKbo8ASzVhwoTW+q677lrtmTlzZmv9ueeeG5SZhsKhhx5aXTvjjDOGcZLe500hAABCIQAAQiEAABEKAQCIUAgAQIRCAADiSJo/qf1j9gP9I/frrrtua/3MM8+s9nz7299urf/+97+v9rztbW9rrR900EHVnq222qq1vv7661d7Hnjggdb6QMcRCWrlAAAQ1ElEQVRznH322dU1GK2mT5/e7REgSTJt2rTq2r/8y7+01nfZZZdqz0YbbdRaf/DBBzsbbBmtscYa1bXddtuttX766adXeyZNmtTxDLXjd55//vmOr9VrvCkEAEAoBABAKAQAIEIhAAARCgEAiN3Hy2WFFVZorR955JHVnr333ru1Pnfu3GrPpptu2tlgA7jhhhuqa1dffXVr/ZOf/OSg3R9Gg4033rjbI0CS5KyzzqqubbHFFh1f75/+6Z9a6/Pmzev4WstioJ3RW2+9dWt9oFNAaq655prq2jnnnNNar/0ZOJZ4UwgAgFAIAIBQCABAhEIAACIUAgAQoRAAgDiS5k9uvPHG1vott9xS7dl22207vs+6667bWl9nnXU6vtbvf//76tqFF17YWv/IRz7S8X1grPnZz35WXRs3rv2/pRcvXjxU48CgOeKII7o9QseeeOKJ6tqPf/zj1vpAf9Y9//zzyz1Tr/KmEAAAoRAAAKEQAIAIhQAARCgEACBJWZZ/aHqZb1bK8N1skKy33nrVtQ996EOt9RNOOKHaU0pprQ/063DGGWe01mv/qHeS/PrXv66uMbiapmn/RR1Go/HZGq3uvffe1vrGG29c7Zk2bVpr/aabbhqUmXqVZyuZOnVqde3DH/5wa/3973//UI3zst13332t9WeffbbaU9v1//Wvf73ac8cdd3Q2GEnqz5Y3hQAACIUAAAiFAABEKAQAIEIhAAARCgEAiCNpYLk5NmNsOeSQQ1rr3/zmN6s91157bWu9dqRIktx1110dzdWLPFsDW2mllVrrtc/RJDn55JNb66985SurPZdeemlr/aqrrqr2zJgxo7X+2GOPVXsYPo6kAQCgSigEAEAoBABAKAQAIEIhAACx+xiWmx2SY8vkyZNb6z/4wQ+qPTvvvHNr/Uc/+lG159BDD22tz58/f4DpeotnC4aG3ccAAFQJhQAACIUAAAiFAABEKAQAIEIhAABxJA0sN8dmkNSPqkmSU045pbV+xBFHVHu23HLL1vpdd93V2WCjmGcLhoYjaQAAqBIKAQAQCgEAEAoBAIhQCABA7D6G5WaHJAwNzxYMDbuPAQCoEgoBABAKAQAQCgEAiFAIAECEQgAAMsxH0gAAMDJ5UwgAgFAIAIBQCABAhEIAACIUAgAQoRAAgAiFAABEKAQAIEIhAAARCgEAiFAIAECEQgAAIhQCABChEACACIUAAEQoBAAgQiEAABEKAQCIUNiTSimbllKeL6Wc3+1ZoBeUUlYqpXyrlDK7lDKvlPKLUso7uz0XjHallKNKKbeWUhaUUr7T7XnGuvHdHoAh8ZUkt3R7COgh45M8mGSHJA8k2S3JD0opb2ya5v5uDgaj3CNJTk4yPcnELs8y5gmFPaaUsl+SOUluSLJJl8eBntA0zfwkJy5R+kkp5bdJtklyfzdmgl7QNM2PkqSU8uYk63d5nDHPl497SCllcpLPJPnHbs8CvayUsk6S1ya5s9uzAAwWobC3nJTkW03TPNjtQaBXlVImJLkgyXebppnV7XkABosvH/eIUsrUJDsneVO3Z4FeVUoZl+R7SRYmOarL4wAMKqGwd+yYZEqSB0opSbJqkhVKKa9vmmbrLs4FPaH0PVjfSrJOkt2apvljl0cCGFRCYe/4epILl/jxsekLiUd0ZRroPeck2TzJzk3TPNftYaAXlFLGpy+LrJC+FxkrJ1nUNM2i7k42Nvk7hT2iaZpnm6Z57MVvSZ5J8nzTNE92ezYY7UopGyb5UJKpSR4rpTzT/+2ALo8Go90JSZ5L8rEkB/Z//4SuTjSGlaZpuj0DAABd5k0hAABCIQAAQiEAABEKAQCIUAgAQIb5nMJSiq3O9JymaUq3Z/Bs0Ys8WzA0as+WN4UAAAiFAAAIhQAARCgEACBCIQAAEQoBAIhQCABAhEIAACIUAgAQoRAAgAiFAABEKAQAIEIhAAARCgEAiFAIAECEQgAAIhQCABChEACACIUAAEQoBAAgQiEAABEKAQCIUAgAQIRCAAAiFAIAEKEQAIAIhQAARCgEACBCIQAAEQoBAEgyvtsDMPbstNNOrfULLrig2rPDDju01u+5555BmQmW1yte8Yrq2qqrrtpaf9e73lXtWXvttVvrp59+erVnwYIF1TUYThMmTGitb7fddtWeU089tbX+l3/5l4MyE0vnTSEAAEIhAABCIQAAEQoBAIhQCABAhEIAANKjR9Jsv/32rfU111yz2nPJJZcM1Ti8xLbbbttav+WWW4Z5Emg3ZcqU6trxxx/fWn/7299e7dliiy2Wd6Q/WW+99aprRx999KDdB5bHaqut1lq/+uqrqz2PPfZYa33dddftuIdl400hAABCIQAAQiEAABEKAQCIUAgAQHp09/GOO+7YWt90002rPXYfD65x4+r/vbHRRhu11jfccMNqTylluWdibNpss82qa8ccc0xr/YADDqj2TJw4sbU+0Ofogw8+2FqfN29etWfzzTdvre+zzz7VnrPPPru1PmvWrGoPjBS1XcZ2Hw8fbwoBABAKAQAQCgEAiFAIAECEQgAAIhQCAJAePZLm4IMPbq3feOONwzzJ2LXeeutV1w477LDW+vnnn1/tcaQGSbLaaqtV1z7/+c+31vfdd99qzyte8YrlnulFv/rVr6pr06dPb61PmDCh2lP7nF9rrbWqPQOtwUjn6LHu86YQAAChEAAAoRAAgAiFAABEKAQAID26+3jcOFm32775zW923DPQ7k1Ikve85z3VtQ9+8IPDMsN9993XWt9ll12qPQ8++GBrfZNNNhmUmaAXNE3TWl955ZWHeZKxS3oCAEAoBABAKAQAIEIhAAARCgEAiFAIAEBG8ZE0W265ZXVtnXXWGcZJaLPaaqt13HPVVVcNwST0kve9732Der3777+/tX7LLbdUe44//vjWeu3YmYFsvvnmHffAWPPmN7+5unbTTTcN4yS9z5tCAACEQgAAhEIAACIUAgAQoRAAgIzi3ce77bZbdW3ixInDOMnYVtvpvdFGG3V8rYcffnh5x6HHHXbYYdW1ww8/vLV+5ZVXVnt+/etft9afeOKJzgZbRk5KoFctWrSotf70009Xe2qnVrzmNa8ZlJlYOm8KAQAQCgEAEAoBAIhQCABAhEIAACIUAgCQUXwkzete97qOe+68884hmGRsO+2001rrAx21ce+997bW582bNygz0bseeeSR6tqJJ544fIMMkre//e3dHgGGxJw5c1rrP/vZz6o9u++++1CNw8vkTSEAAEIhAABCIQAAEQoBAIhQCABARvHu42Vxyy23dHuErps8eXJ17R3veEdr/cADD6z27Lrrrh3PcNJJJ7XWa7vVYLgdffTR1bVVVlll0O7zxje+seOeG264obp24403Ls84wBjnTSEAAEIhAABCIQAAEQoBAIhQCABAhEIAADLGjqRZY401huU+W221VXWtlNJa33nnnas966+/fmt9xRVXrPYccMABrfVx4+r/HfDcc8+11m+++eZqz4IFC1rr48fXP7X+8z//s7oGy2rSpEmt9de//vXVnk996lOt9d12263j+w/0bC1evLjj6z3yyCOt9UMPPbTa88ILL3R8Hxjp1lxzzW6PMGZ4UwgAgFAIAIBQCABAhEIAACIUAgCQUbz7uLZTNkmapmmtf/WrX632fPzjH1/umV605ZZbVtdqu48XLVpU7Xn22Wdb63fddVe159vf/nZr/dZbb632XHvtta31xx9/vNrz0EMPtdYnTpxY7Zk1a1Z1DZJkwoQJrfU3velN1Z6LL764tb7eeutVe2q/j9R2/ibJjTfe2Fp/xzveUe2p7YweSG0H/3vf+95qzxlnnNFaX7hwYcf3h5Fijz326PYIY4Y3hQAACIUAAAiFAABEKAQAIEIhAAARCgEAyCg+kubII4+srs2ePbu1vt122w3VOP/NAw88UF279NJLW+t33313teemm25a7pmWx+GHH15dW3vttVvrv/nNb4ZqHHrEiiuuWF2rHe/yox/9qOP7fPrTn66uzZw5s7V+/fXXV3vWWGONjq6VJFtssUV1rab2bH32s5+t9tR+76n9vpMkCxYs6GwwWA5XX311dW333Xcfxklo400hAABCIQAAQiEAABEKAQCIUAgAQEbx7uOBfP7zn+/2CD1lp5126rjn4osvHoJJGI0mTJjQWh9oV/Bxxx3X8X0uv/zy1vqXv/zlas+cOXNa67Wdv0ny05/+tLX+xje+sdqzcOHC1voXvvCFak9tx/Kee+5Z7bngggta6//+7/9e7an9fvnUU09Ve2puv/32jnsYWwY6naOm9ntIkmy44Yat9dopJAzMm0IAAIRCAACEQgAAIhQCABChEACACIUAAKRHj6Sh+y655JJuj8AwWmGFFaprJ510Umv92GOPrfbMnz+/tf6xj32s2nPhhRe21mvHziTJm9/85tb6WWedVe1505ve1Fr/1a9+Ve054ogjWutXX311tWfy5Mmt9e22267ac8ABB7TW99hjj2rPVVddVV2refDBB1vrG220UcfXYmxZtGhRxz2llOraSiuttDzj8BLeFAIAIBQCACAUAgAQoRAAgAiFAADE7mNgEBx++OHVtdou42effbba86EPfai1fuWVV1Z73va2t7XWDz300GrPO9/5ztb6xIkTqz2f+cxnWuvnnntutae2W3cgc+fOba3/27/9W7Wntrb//vtXe/72b/+2s8GSfPSjH+24B5JkxowZ1bVZs2a11jfbbLNqzzHHHNNaP/LIIzsbjCTeFAIAEKEQAIAIhQAARCgEACBCIQAAEQoBAEhSmqYZvpuVMnw3Y9BcdNFF1bV99tmntf7+97+/2nPeeect90wjSdM09X+tfZh0+9l69NFHq2trr712a33BggXVntrRFKusskq1Z5NNNqmuderEE0+srn32s59trb/wwguDdn/6eLbGln/9139trQ90rNQ666zTWn/++ecHZaZeVXu2vCkEAEAoBABAKAQAIEIhAAARCgEASDK+2wMwutV2r48b5783xpLHHnusulbbfbzSSitVe7baaquOZ/jpT3/aWr/uuuuqPZdeemlr/f7776/22GUMw2ugU1IWLlw4jJP0Pn9yAwAgFAIAIBQCABChEACACIUAAEQoBAAgjqRhiLz97W+vrn3nO98ZvkEYFttvv311ba+99mqtb7311tWeJ554orX+7W9/u9rz1FNPtdYdWQGj2+TJk6tre+65Z2v9kksuGapxepo3hQAACIUAAAiFAABEKAQAIEIhAACx+5jlVErp9giMAPPmzauufe973+uoDoxN++yzT2t9wYIF1Z677757qMYZk7wpBABAKAQAQCgEACBCIQAAEQoBAIhQCABAHEnDy3D55ZdX1973vvcN4yQA9Krrrruutb755ptXe5577rmhGmdM8qYQAAChEAAAoRAAgAiFAABEKAQAIElpmmb4blbK8N0MhknTNKXbM3i26EWeLRgatWfLm0IAAIRCAACEQgAAIhQCABChEACACIUAAEQoBAAgQiEAABEKAQCIUAgAQIRCAAAiFAIAEKEQAIAIhQAARCgEACBCIQAAEQoBAIhQCABAhEIAAJKUpmm6PQMAAF3mTSEAAEIhAABCIQAAEQoBAIhQCABAhEIAACIUAgAQoRAAgAiFAABEKAQAIEIhAAARCgEAiFAIAECEQgAAIhQCABChEACACIUAAEQoBAAgQiEAABEKAQCIUAgAQIRCAAAiFAIAkOT/B69J5af08Uz6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "batch_size = 100\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# plot the first 9 training images in MNIST\n",
    "fig, ax = plt.subplots(3, 3, figsize = (10, 10))\n",
    "fig.suptitle('First 9 images in MNIST')\n",
    "fig.tight_layout(pad = 0.3, rect = [0, 0, 0.9, 0.9])\n",
    "for x, y in [(i, j) for i in range(3) for j in range(3)]:\n",
    "    ax[x, y].axis('off')\n",
    "    ax[x, y].imshow(x_train[x + y * 3,:,:,:].reshape((28,28)), cmap = 'gray')\n",
    "    ax[x, y].set_title(np.where(y_train[x + y * 3])[0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "59900/60000 [============================>.] - ETA: 0s - loss: 0.2004 - acc: 0.9380- ETA: 5s - loss:  - ETA: 1s - loss: 0.2023 - a"
     ]
    }
   ],
   "source": [
    "# The model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(5, 5), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "history = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "# Evaluation\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d72c630cc631>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfigsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Plot training & validation accuracy\n",
    "figsize = (8,5)\n",
    "plt.figure(figsize=figsize)\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=figsize)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3, 4pts\n",
    "\n",
    "There is a competition https://www.kaggle.com/c/dogs-vs-cats-iminit-2018. You should\n",
    "have at least 75% accuracy on the public leaderboard to get basic points on this\n",
    "exercise. The first 3 places will have extra points (5 for the first place, and 4 for\n",
    "the second and the third place). Use all your knowledge and experience to attack\n",
    "the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-4f2dac072112>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mminT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mmaxT\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mCatCollection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mminT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaxT\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mminT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from skimage import io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2 as cv \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "cat_data_path_str = 'C:/Users/Hong/Desktop/all/cats_vs_dogs/cat.*.jpg'\n",
    "Catimages = io.ImageCollection(cat_data_path_str)\n",
    "\n",
    "dog_data_path_str = 'C:/Users/Hong/Desktop/all/cats_vs_dogs/dog.*.jpg'\n",
    "Dogimages = io.ImageCollection(dog_data_path_str)\n",
    "\n",
    "CatCollection = []\n",
    "DogCollection = []\n",
    "\n",
    "for i in range(len(Catimages)):\n",
    "    temp = cv.resize(Catimages[i],(128,128))\n",
    "    minT = temp.min()\n",
    "    maxT = temp.max()\n",
    "    CatCollection.append((temp-minT)/(maxT-minT))\n",
    "    \n",
    "for i in range(len(Dogimages)):\n",
    "    temp = cv.resize(Dogimages[i],(128,128))\n",
    "    minT = temp.min()\n",
    "    maxT = temp.max()\n",
    "    DogCollection.append((temp-minT)/(maxT-minT))\n",
    "\n",
    "Dog = np.array(DogCollection)\n",
    "Dog_y = np.ones(Dog.shape[0])\n",
    "\n",
    "Cat = np.array(CatCollection)\n",
    "Cat_y = np.zeros(Cat.shape[0])\n",
    "\n",
    "\n",
    "x = np.concatenate((Dog,Cat),axis = 0)\n",
    "y = np.concatenate((Dog_y,Cat_y),axis = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.4)\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(1, 2, figsize = (10, 10))\n",
    "\n",
    "# ax[0].imshow(X_train[0])\n",
    "# ax[1].imshow(X_train[10])\n",
    "# print(y_train[0],y_train[10])\n",
    "\n",
    "print('x_train shape:', X_train.shape)\n",
    "print('x_test shape:', X_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "\n",
    "X_train_reshaped = X_train.reshape(X_train.size)\n",
    "X_test_reshaped = X_test.reshape(X_test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # mean_image = x.mean(axis=(0))\n",
    "# for i in range(x.shape[0]):\n",
    "#     x[i] = x[i] - mean_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataframe = pd.DataFrame({'y_train':y_train})\n",
    "dataframe.to_csv('C:/Users/Hong/Desktop/all/y_train.csv',index=False,sep=',')\n",
    "\n",
    "dataframe = pd.DataFrame({'y_test':y_test})\n",
    "dataframe.to_csv('C:/Users/Hong/Desktop/all/y_test.csv',index=False,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存成功1\n",
      "保存成功2\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('C:/Users/Hong/Desktop/all/X_train_reshaped.bin' , mode='wb') as f:\n",
    "    pickle.dump(X_train_reshaped,f)\n",
    "    \n",
    "with open('C:/Users/Hong/Desktop/all/X_test_reshaped.bin' , mode='wb') as f:\n",
    "    pickle.dump(X_test_reshaped,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (11251, 128, 128, 3)\n",
      "x_test shape: (7501, 128, 128, 3)\n",
      "y_train shape: (11251,)\n",
      "y_test shape: (7501,)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "with open('C:/Users/Hong/Desktop/all/X_test_reshaped.bin',mode='rb') as f:\n",
    "    arr = pickle.load(f) \n",
    "X_test = arr.reshape([7501,128,128,3])\n",
    "\n",
    "with open('C:/Users/Hong/Desktop/all/X_train_reshaped.bin',mode='rb') as f:\n",
    "    arr = pickle.load(f) \n",
    "X_train = arr.reshape([11251,128,128,3])\n",
    "\n",
    "df = pd.read_csv('C:/Users/Hong/Desktop/all/y_train.csv')\n",
    "y_train = df.values.reshape(df.values.size)\n",
    "\n",
    "df = pd.read_csv('C:/Users/Hong/Desktop/all/y_test.csv')\n",
    "y_test = df.values.reshape(df.values.size)\n",
    "\n",
    "\n",
    "print('x_train shape:', X_train.shape)\n",
    "print('x_test shape:', X_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11251 samples, validate on 7501 samples\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "input_shape = (128, 128, 3)\n",
    "batch_size = 100\n",
    "num_classes = 1\n",
    "epochs = 10\n",
    "\n",
    "# The model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "# model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(4096, activation='relu'))\n",
    "# model.add(Dropout(0.25))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training\n",
    "history = model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluation\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [3 4 5]]\n",
      "(2, 3)\n",
      "[2. 3. 4.]\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
